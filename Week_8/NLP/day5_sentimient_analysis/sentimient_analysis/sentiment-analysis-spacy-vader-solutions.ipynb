{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Sentiment Analysis of Movie Reviews with Spacy and VADER\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "- Understand the goal of basic sentiment analysis.\n",
    "- Calculate sentiment scores manually using a reviews dataset and scores tagged by word.\n",
    "- Practice using the spacy parser to get out part of speech tags from text.\n",
    "- Fit a model using sentiment and grammar features.\n",
    "- Use the VADER sentiment analyzer to get out more accurate sentiment scores and compare the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Introduction to sentiment analysis](#intro)\n",
    "- [Load the word sentiment dataset](#load-sen)\n",
    "    - [Engineer objectivity and positive difference scores](#adj-scores)\n",
    "    - [Put scores in a part of speech dictionary](#pos-dict)\n",
    "- [Load the rotten tomatoes review dataset](#rt-reviews)\n",
    "    - [Restrict reviews to valid lengths and ratings](#subset)\n",
    "- [Import spacy](#spacy)\n",
    "    - [Parse all the quotes using spacy's multithreaded parser](#multi)\n",
    "- [Part of speech features](#pos-features)\n",
    "- [Assign sentiment scores](#assign)\n",
    "- [Print out the most positive and most negative reviews](#print-most)\n",
    "- [Print out the most objective and most subjective reviews](#print-most-obj)\n",
    "- [Build a model to classify fresh vs. rotten with the sentiment and grammar features](#model)\n",
    "- [User the VADER library to get better sentiment scores](#vader)\n",
    "    - [Build a model using the VADER sentiment features](#vader-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "\n",
    "## Introduction to sentiment analysis\n",
    "---\n",
    "\n",
    "Sentiment analysis is one of the most popular topics in NLP. Most commonly it is the quantification of text into valence and subjectivity scores.\n",
    "\n",
    "First we will load in a dataset of pre-coded sentiment scores for positivity and negativity on words. These words are also tagged with their part of speech in the sentence. We can use these valence scores to evaluate the sentiment of rottentomatoes movie reviews. Many packages such as TextBlob come pre-packaged with sentiment scores for words after parsing text, but doing the sentiment parsing manually will show you how it can be done without any \"magic\".\n",
    "\n",
    "We will also explore a more advanced sentiment analysis library in python: [VADER](https://github.com/cjhutto/vaderSentiment). We can parse the sentiment of the movie reviews using this package and compare it to our more basic method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load-sen'></a>\n",
    "\n",
    "## Load the word sentiment dataset\n",
    "---\n",
    "\n",
    "Below we will load in some pre-tagged positive and negative valence scores for a dictionary of words. Each row of the dataset contains the part of speech, the word, the positive score, and the negative score for the word. A word may appear more than once if it can appear with different part of speech tags. \n",
    "\n",
    "These scores are designed so that we can also derive the *objectivity score* of the word from the positive and negative scores.\n",
    "\n",
    "Objectivity is calculated: \n",
    "\n",
    "    1. - (positive_score + negative_score)\n",
    "\n",
    "Thus if a score has zero positive score and negative score it is completely objective. If a score has, for example, 0.5 positive and 0.5 negative, it may not be any more positive than negative but we can tell that it is subjective (objectivity = 0.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sen = pd.read_csv('./datasets/sentiment_words_simple.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155287"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adj</td>\n",
       "      <td>.22-caliber</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adj</td>\n",
       "      <td>.22-calibre</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adj</td>\n",
       "      <td>.22_caliber</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adj</td>\n",
       "      <td>.22_calibre</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj</td>\n",
       "      <td>.38-caliber</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pos         word  pos_score  neg_score\n",
       "0  adj  .22-caliber        0.0        0.0\n",
       "1  adj  .22-calibre        0.0        0.0\n",
       "2  adj  .22_caliber        0.0        0.0\n",
       "3  adj  .22_calibre        0.0        0.0\n",
       "4  adj  .38-caliber        0.0        0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make the part of speech tags uppercase (this will come in handy later when we use Spacy).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sen.pos = sen.pos.map(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='adj-scores'></a>\n",
    "\n",
    "### Engineer objectivity and positive difference scores\n",
    "\n",
    "Since subjective vs. objective is embedded in the positive and negative scores, we should extract this and convert the positive and negative into a relative difference scores.\n",
    "\n",
    "**Calculate two new scores:**\n",
    "\n",
    "    objectivity = 1. - (pos_score + neg_score)\n",
    "    pos_vs_neg = pos_score - neg_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sen['objectivity'] = 1. - (sen.pos_score + sen.neg_score)\n",
    "sen['pos_vs_neg'] = sen.pos_score - sen.neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "      <th>objectivity</th>\n",
       "      <th>pos_vs_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>.22-caliber</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>.22-calibre</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>.22_caliber</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pos         word  pos_score  neg_score  objectivity  pos_vs_neg\n",
       "0  ADJ  .22-caliber        0.0        0.0          1.0         0.0\n",
       "1  ADJ  .22-calibre        0.0        0.0          1.0         0.0\n",
       "2  ADJ  .22_caliber        0.0        0.0          1.0         0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pos-dict'></a>\n",
    "\n",
    "### Put scores in a part of speech dictionary\n",
    "\n",
    "The dictionary format of the data will be much easier to index using our parsing functions later on. Create a dictionary where the keys are the four part of speech tags:\n",
    "\n",
    "    ADJ\n",
    "    NOUN\n",
    "    VERB\n",
    "    ADV\n",
    "\n",
    "For each key, store a dictionary that contains all of the words for that part of speech with their objectivity and positive vs. negative scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n"
     ]
    }
   ],
   "source": [
    "sen_dict = {'ADJ':{},'NOUN':{},'VERB':{},'ADV':{}}\n",
    "\n",
    "for i, row in enumerate(sen.itertuples()):\n",
    "    if (i % 10000) == 0:\n",
    "        print i\n",
    "    sen_dict[row[1]][row[2]] = {'objectivity':row[5], 'pos_vs_neg':row[6]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rt-reviews'></a>\n",
    "\n",
    "## Load the rotten tomatoes reviews dataset\n",
    "\n",
    "---\n",
    "\n",
    "This dataset has:\n",
    "    \n",
    "    critic: critic's name\n",
    "    fresh: fresh vs. rotten rating\n",
    "    imdb: code for imdb\n",
    "    publication: where the review was published\n",
    "    quote: the review snippet\n",
    "    review_date: date of review\n",
    "    rtid: rottentomatoes id\n",
    "    title: name of movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt = pd.read_csv('./datasets/rt_critics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Richard Corliss</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>The year's most inventive comedy.</td>\n",
       "      <td>2008-08-31</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "      <td>2008-03-10</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh      imdb     publication  \\\n",
       "0         Derek Adams  fresh  114709.0        Time Out   \n",
       "1     Richard Corliss  fresh  114709.0   TIME Magazine   \n",
       "2         David Ansen  fresh  114709.0        Newsweek   \n",
       "3       Leonard Klady  fresh  114709.0         Variety   \n",
       "4  Jonathan Rosenbaum  fresh  114709.0  Chicago Reader   \n",
       "\n",
       "                                               quote review_date    rtid  \\\n",
       "0  So ingenious in concept, design and execution ...  2009-10-04  9559.0   \n",
       "1                  The year's most inventive comedy.  2008-08-31  9559.0   \n",
       "2  A winning animated feature that has something ...  2008-08-18  9559.0   \n",
       "3  The film sports a provocative and appealing st...  2008-06-09  9559.0   \n",
       "4  An entertaining computer-generated, hyperreali...  2008-03-10  9559.0   \n",
       "\n",
       "       title  \n",
       "0  Toy story  \n",
       "1  Toy story  \n",
       "2  Toy story  \n",
       "3  Toy story  \n",
       "4  Toy story  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='subset'></a>\n",
    "\n",
    "### Restrict data to reviews with valid ratings and reviews over 10 words long\n",
    "\n",
    "Also clean up the reviews, making a column with the case and punctuation removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt = rt[rt.fresh.isin(['fresh','rotten'])]\n",
    "rt.fresh = rt.fresh.map(lambda x: 1 if x == 'fresh' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11215, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt['quote_len'] = rt.quote.map(lambda x: len(x.split()))\n",
    "rt = rt[rt.quote_len > 10]\n",
    "rt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "rt['qt'] = rt.quote.map(lambda x: unicode(''.join([y for y in list(x.lower()) if y in string.ascii_lowercase+\" -'\"])))\n",
    "rt.qt = rt.qt.map(lambda x: x.replace('-',' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='spacy'></a>\n",
    "\n",
    "## Import spacy\n",
    "\n",
    "---\n",
    "\n",
    "The spacy package is the current gold standard for parsing the grammatical structure of text (aside from neural network architectures). We are going to use it to find the part of speech tags for the review words. \n",
    "\n",
    "Once we have parsed the tags with spacy, we can assign objectivity and valence scores by finding the match in our sentiment dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "# python -m spacy download en\n",
    "en_nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parse a single quote:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = en_nlp(rt.qt.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "so ingenious in concept design and execution that you could watch it on a postage stamp sized screen and still be engulfed by its charm"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "concept"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can get out single words with indexing:\n",
    "tmp[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print out the part of speech tags for each word in the quote:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so ADV\n",
      "ingenious ADJ\n",
      "in ADP\n",
      "concept NOUN\n",
      "design NOUN\n",
      "and CCONJ\n",
      "execution NOUN\n",
      "that ADJ\n",
      "you PRON\n",
      "could VERB\n",
      "watch VERB\n",
      "it PRON\n",
      "on ADP\n",
      "a DET\n",
      "postage NOUN\n",
      "stamp NOUN\n",
      "sized VERB\n",
      "screen NOUN\n",
      "and CCONJ\n",
      "still ADV\n",
      "be VERB\n",
      "engulfed VERB\n",
      "by ADP\n",
      "its ADJ\n",
      "charm NOUN\n"
     ]
    }
   ],
   "source": [
    "for token in tmp:\n",
    "    print token, token.pos_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='multi'></a>\n",
    "### Parse all the quotes using spacy's multithreaded parser\n",
    "\n",
    "Parsing a lot of text can take quite awhile. Luckily spacy comes with multithreading functionality to speed up the process considerably. Below is code that will parse the quotes across multiple threads and assign them to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n"
     ]
    }
   ],
   "source": [
    "parsed_quotes = []\n",
    "for i, parsed in enumerate(en_nlp.pipe(rt.qt.values, batch_size=50, n_threads=4)):\n",
    "    assert parsed.is_parsed\n",
    "    if (i % 1000) == 0:\n",
    "        print i\n",
    "    parsed_quotes.append(parsed)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pos-features'></a>\n",
    "\n",
    "## Create features with part of speech proportions\n",
    "\n",
    "---\n",
    "\n",
    "With our spacy parsed reviews, we have a lot of feature engineering potential even before we get to sentiment. Something simple we could do is calculate the proportion of words in the quote that have each part of speech tag. We can try using these as predictors in a model later.\n",
    "\n",
    "**Find all the unique part of speech categories in the reviews.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'ADJ' u'ADP' u'ADV' u'CCONJ' u'DET' u'INTJ' u'NOUN' u'NUM' u'PART'\n",
      " u'PRON' u'PROPN' u'PUNCT' u'SPACE' u'SYM' u'VERB' u'X']\n"
     ]
    }
   ],
   "source": [
    "unique_pos = []\n",
    "for parsed in parsed_quotes:\n",
    "    unique_pos.extend([t.pos_ for t in parsed])\n",
    "unique_pos = np.unique(unique_pos)\n",
    "print unique_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the proportion columns for each part of speech.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pos in unique_pos:\n",
    "    rt[pos+'_prop'] = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iterate through the reviews and calculate the proportions of each part of speech tag.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n"
     ]
    }
   ],
   "source": [
    "rt = rt.reset_index(drop=True)\n",
    "for i, parsed in enumerate(parsed_quotes):\n",
    "    if (i % 1000) == 0:\n",
    "        print i\n",
    "    parsed_len = len(parsed)\n",
    "    for pos in unique_pos:\n",
    "        count = len([x for x in parsed if x.pos_ == pos])\n",
    "        rt.ix[i, pos+'_prop'] = float(count)/parsed_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "      <th>quote_len</th>\n",
       "      <th>qt</th>\n",
       "      <th>...</th>\n",
       "      <th>NOUN_prop</th>\n",
       "      <th>NUM_prop</th>\n",
       "      <th>PART_prop</th>\n",
       "      <th>PRON_prop</th>\n",
       "      <th>PROPN_prop</th>\n",
       "      <th>PUNCT_prop</th>\n",
       "      <th>SPACE_prop</th>\n",
       "      <th>SYM_prop</th>\n",
       "      <th>VERB_prop</th>\n",
       "      <th>X_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>24</td>\n",
       "      <td>so ingenious in concept design and execution t...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>13</td>\n",
       "      <td>a winning animated feature that has something ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>17</td>\n",
       "      <td>the film sports a provocative and appealing st...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "      <td>2008-03-10</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>14</td>\n",
       "      <td>an entertaining computer generated hyperrealis...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michael Booth</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Denver Post</td>\n",
       "      <td>As Lion King did before it, Toy Story revived ...</td>\n",
       "      <td>2007-05-03</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>40</td>\n",
       "      <td>as lion king did before it toy story revived t...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh      imdb     publication  \\\n",
       "0         Derek Adams      1  114709.0        Time Out   \n",
       "1         David Ansen      1  114709.0        Newsweek   \n",
       "2       Leonard Klady      1  114709.0         Variety   \n",
       "3  Jonathan Rosenbaum      1  114709.0  Chicago Reader   \n",
       "4       Michael Booth      1  114709.0     Denver Post   \n",
       "\n",
       "                                               quote review_date    rtid  \\\n",
       "0  So ingenious in concept, design and execution ...  2009-10-04  9559.0   \n",
       "1  A winning animated feature that has something ...  2008-08-18  9559.0   \n",
       "2  The film sports a provocative and appealing st...  2008-06-09  9559.0   \n",
       "3  An entertaining computer-generated, hyperreali...  2008-03-10  9559.0   \n",
       "4  As Lion King did before it, Toy Story revived ...  2007-05-03  9559.0   \n",
       "\n",
       "       title  quote_len                                                 qt  \\\n",
       "0  Toy story         24  so ingenious in concept design and execution t...   \n",
       "1  Toy story         13  a winning animated feature that has something ...   \n",
       "2  Toy story         17  the film sports a provocative and appealing st...   \n",
       "3  Toy story         14  an entertaining computer generated hyperrealis...   \n",
       "4  Toy story         40  as lion king did before it toy story revived t...   \n",
       "\n",
       "    ...    NOUN_prop  NUM_prop  PART_prop  PRON_prop  PROPN_prop  PUNCT_prop  \\\n",
       "0   ...     0.280000       0.0   0.000000   0.080000         0.0         0.0   \n",
       "1   ...     0.384615       0.0   0.000000   0.000000         0.0         0.0   \n",
       "2   ...     0.277778       0.0   0.000000   0.000000         0.0         0.0   \n",
       "3   ...     0.437500       0.0   0.000000   0.000000         0.0         0.0   \n",
       "4   ...     0.302326       0.0   0.023256   0.046512         0.0         0.0   \n",
       "\n",
       "   SPACE_prop  SYM_prop  VERB_prop  X_prop  \n",
       "0      0.0000       0.0   0.200000     0.0  \n",
       "1      0.0000       0.0   0.230769     0.0  \n",
       "2      0.0000       0.0   0.055556     0.0  \n",
       "3      0.0625       0.0   0.125000     0.0  \n",
       "4      0.0000       0.0   0.139535     0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assign'></a>\n",
    "\n",
    "## Assign sentiment scores\n",
    "---\n",
    "\n",
    "We will now use the parsed reviews and the sentiment dataset to assign the average objectivity and positive vs. negative scores.\n",
    "\n",
    "If a word cannot be found in the dataset we can ignore it. If a review has no words that match something in our dataset, will can assign overall neutral scores of `objectivity = 1` and `pos_vs_neg = 0`.\n",
    "\n",
    "There are definitely problems with this approach, but for now we can keep it \"dumb\" and see if things improve when we use the VADER analyzer later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n"
     ]
    }
   ],
   "source": [
    "def scorer(parsed):\n",
    "    obj_scores, pvn_scores = [], []\n",
    "    for token in [t for t in parsed if t.pos_ in ['NOUN','VERB','ADV','ADJ']]:\n",
    "        try:\n",
    "            obj_scores.append(sen_dict[token.pos_][str(token)]['objectivity'])\n",
    "            pvn_scores.append(sen_dict[token.pos_][str(token)]['pos_vs_neg'])\n",
    "        except:\n",
    "            pass\n",
    "    if len(obj_scores) == 0:\n",
    "        obj_scores = [1.]\n",
    "    if len(pvn_scores) == 0:\n",
    "        pvn_scores = [0.]\n",
    "    return [obj_scores, pvn_scores]\n",
    "\n",
    "\n",
    "scores = []\n",
    "for i, parsed in enumerate(parsed_quotes):\n",
    "    if (i % 1000) == 0:\n",
    "        print i\n",
    "    scores.append(scorer(parsed))\n",
    "    \n",
    "rt['objectivity_avg'] = [np.mean(x[0]) for x in scores]\n",
    "rt['pos_vs_neg_avg'] = [np.mean(x[1]) for x in scores]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "      <th>quote_len</th>\n",
       "      <th>qt</th>\n",
       "      <th>...</th>\n",
       "      <th>PART_prop</th>\n",
       "      <th>PRON_prop</th>\n",
       "      <th>PROPN_prop</th>\n",
       "      <th>PUNCT_prop</th>\n",
       "      <th>SPACE_prop</th>\n",
       "      <th>SYM_prop</th>\n",
       "      <th>VERB_prop</th>\n",
       "      <th>X_prop</th>\n",
       "      <th>objectivity_avg</th>\n",
       "      <th>pos_vs_neg_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>24</td>\n",
       "      <td>so ingenious in concept design and execution t...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.876202</td>\n",
       "      <td>0.061813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>13</td>\n",
       "      <td>a winning animated feature that has something ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>17</td>\n",
       "      <td>the film sports a provocative and appealing st...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.075284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "      <td>2008-03-10</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>14</td>\n",
       "      <td>an entertaining computer generated hyperrealis...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.850521</td>\n",
       "      <td>0.048438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michael Booth</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Denver Post</td>\n",
       "      <td>As Lion King did before it, Toy Story revived ...</td>\n",
       "      <td>2007-05-03</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>40</td>\n",
       "      <td>as lion king did before it toy story revived t...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.901589</td>\n",
       "      <td>0.053068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh      imdb     publication  \\\n",
       "0         Derek Adams      1  114709.0        Time Out   \n",
       "1         David Ansen      1  114709.0        Newsweek   \n",
       "2       Leonard Klady      1  114709.0         Variety   \n",
       "3  Jonathan Rosenbaum      1  114709.0  Chicago Reader   \n",
       "4       Michael Booth      1  114709.0     Denver Post   \n",
       "\n",
       "                                               quote review_date    rtid  \\\n",
       "0  So ingenious in concept, design and execution ...  2009-10-04  9559.0   \n",
       "1  A winning animated feature that has something ...  2008-08-18  9559.0   \n",
       "2  The film sports a provocative and appealing st...  2008-06-09  9559.0   \n",
       "3  An entertaining computer-generated, hyperreali...  2008-03-10  9559.0   \n",
       "4  As Lion King did before it, Toy Story revived ...  2007-05-03  9559.0   \n",
       "\n",
       "       title  quote_len                                                 qt  \\\n",
       "0  Toy story         24  so ingenious in concept design and execution t...   \n",
       "1  Toy story         13  a winning animated feature that has something ...   \n",
       "2  Toy story         17  the film sports a provocative and appealing st...   \n",
       "3  Toy story         14  an entertaining computer generated hyperrealis...   \n",
       "4  Toy story         40  as lion king did before it toy story revived t...   \n",
       "\n",
       "        ...        PART_prop  PRON_prop  PROPN_prop  PUNCT_prop  SPACE_prop  \\\n",
       "0       ...         0.000000   0.080000         0.0         0.0      0.0000   \n",
       "1       ...         0.000000   0.000000         0.0         0.0      0.0000   \n",
       "2       ...         0.000000   0.000000         0.0         0.0      0.0000   \n",
       "3       ...         0.000000   0.000000         0.0         0.0      0.0625   \n",
       "4       ...         0.023256   0.046512         0.0         0.0      0.0000   \n",
       "\n",
       "   SYM_prop  VERB_prop  X_prop  objectivity_avg  pos_vs_neg_avg  \n",
       "0       0.0   0.200000     0.0         0.876202        0.061813  \n",
       "1       0.0   0.230769     0.0         1.000000        0.000000  \n",
       "2       0.0   0.055556     0.0         0.840909        0.075284  \n",
       "3       0.0   0.125000     0.0         0.850521        0.048438  \n",
       "4       0.0   0.139535     0.0         0.901589        0.053068  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='print-most'></a>\n",
    "## Print out the most positive and most negative reviews\n",
    "---\n",
    "\n",
    "Now that we have the average valence for reviews, try printing out the top 10 most positive and top 10 most negative reviews to visually verify that our approach makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streep (the best thing she has done in ages) carries it along.\n",
      "============================================================\n",
      "\n",
      "High Noon combines its points about good citizenship with some excellent picturemaking.\n",
      "============================================================\n",
      "\n",
      "Paths of Glory is all about that greatest of all movie subjects: power.\n",
      "============================================================\n",
      "\n",
      "Improbabilities and all, Simpatico still boasts wonderful scenes and a cast that is truly superb.\n",
      "============================================================\n",
      "\n",
      "As bustling and impassioned as the best Sturges and Capra movies.\n",
      "============================================================\n",
      "\n",
      "From Russia with Love is a preposterous, skillful slab of hardhitting, sexy hokum.\n",
      "============================================================\n",
      "\n",
      "Succeeds, in part, because the film is as non-judgmental as the famed sex researcher himself.\n",
      "============================================================\n",
      "\n",
      "It's an excellent movie for kids, because it is about how amazing children can be.\n",
      "============================================================\n",
      "\n",
      "Is Dr. Strangelove Kubrick's best movie? Along with Paths of Glory, absolutely.\n",
      "============================================================\n",
      "\n",
      "Hanks is superb, reemploying the childlike presence he brought to Big.\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rt.sort_values('pos_vs_neg_avg', ascending=False, inplace=True)\n",
    "for quote in rt.quote[0:10]:\n",
    "    print quote\n",
    "    print '============================================================\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What pulls you over the bum spots is the electrifying immediacy.\n",
      "============================================================\n",
      "\n",
      "Unoriginal and insulting, 3 Strikes goes down without scoring a single chuckle.\n",
      "============================================================\n",
      "\n",
      "Brooding, somber film is ragged around the edges and not without problematic aspects.\n",
      "============================================================\n",
      "\n",
      "Its tone is never exactly comedic and its horrific touches are more disgusting than scary.\n",
      "============================================================\n",
      "\n",
      "It's a disturbing, hopeless, irredeemable series of images that will scar you if you wander into it unprepared.\n",
      "============================================================\n",
      "\n",
      "...Liar Liar stands to make a liar out of those who predicted that Carrey's career was on the skids.\n",
      "============================================================\n",
      "\n",
      "A silly movie, with silly jokes and a silly story. But the talents at work in it are not silly.\n",
      "============================================================\n",
      "\n",
      "Likely to be disappointing to Almodovar's admirers, and inexplicable to anyone else.\n",
      "============================================================\n",
      "\n",
      "It retains the cheesy look of the 1979 original, pure schlock not gussied up to appear to be anything else.\n",
      "============================================================\n",
      "\n",
      "Both bleak and bleakly funny, appalling in its excesses and exhilarating in its execution.\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rt.sort_values('pos_vs_neg_avg', ascending=True, inplace=True)\n",
    "for quote in rt.quote[0:10]:\n",
    "    print quote\n",
    "    print '============================================================\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='print-most-obj'></a>\n",
    "\n",
    "## Print out the most objective and most subjective reviews\n",
    "---\n",
    "\n",
    "Do the same as above, but now sort by the objectivity. What kind of differences do you notice between these? Does our approach actually appear to capture meaningful subjectivity and objectivity in the reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Dolittle runs out of ideas long before the projector runs out of film.\n",
      "============================================================\n",
      "\n",
      "The funniest movie of 1975 and probably the silliest movie ever made.\n",
      "============================================================\n",
      "\n",
      "Either they had something on [Nick Gomez] or he needed the money.\n",
      "============================================================\n",
      "\n",
      "Some of the funniest scenes bounce off the nightmares of every bride and groom before the wedding.\n",
      "============================================================\n",
      "\n",
      "Everything about Something to Talk About feels off by a few beats.\n",
      "============================================================\n",
      "\n",
      "By the end of the film, Selena has been all but canonized.\n",
      "============================================================\n",
      "\n",
      "Magnolia makes it three-for-three for writer and director Paul Thomas Anderson\n",
      "============================================================\n",
      "\n",
      "It plays like a movie dreamed up by people in a studio marketing department who'd decided to bare their souls.\n",
      "============================================================\n",
      "\n",
      "Barbara Stanwyck is the sexiest con woman ever captured on film.\n",
      "============================================================\n",
      "\n",
      "Offers an abundance of pleasures, especially in the realm of characterization and atmosphere.\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rt.sort_values('objectivity_avg', ascending=False, inplace=True)\n",
    "for quote in rt.quote[0:10]:\n",
    "    print quote\n",
    "    print '============================================================\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They keep getting worse and worse and worse . . .\n",
      "============================================================\n",
      "\n",
      "At its best when it's being lighthearted and at its weakest when it takes a halfhearted stab at semi-seriousness.\n",
      "============================================================\n",
      "\n",
      "At its best, it's a valentine of venom, sent with mirth and malice aforethought.\n",
      "============================================================\n",
      "\n",
      "What pulls you over the bum spots is the electrifying immediacy.\n",
      "============================================================\n",
      "\n",
      "I am not sure why this isn't very funny, but it's not.\n",
      "============================================================\n",
      "\n",
      "Hawthorne is by turn outrageous and pathetic and imperious and poignant and very funny.\n",
      "============================================================\n",
      "\n",
      "At its best, this achieves the beauty and grandeur of a Kurosawa epic -- at its worst, however, it feels like a Python remake of The Vikings.\n",
      "============================================================\n",
      "\n",
      "In spite of its shortcomings, children love these characters and will enjoy Tigger.\n",
      "============================================================\n",
      "\n",
      "Hilarious, sexy, clever, playful and as initially teasing as it is ultimately satisfying.\n",
      "============================================================\n",
      "\n",
      "Jumps adroitly between the macho and anti-macho, the romantic and anti-romantic.\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rt.sort_values('objectivity_avg', ascending=True, inplace=True)\n",
    "for quote in rt.quote[0:10]:\n",
    "    print quote\n",
    "    print '============================================================\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There doesn't seem to be much signal in the objectivity score. They look pretty\n",
    "# similar to me!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model'></a>\n",
    "\n",
    "## Build a model to classify fresh vs. rotten with the sentiment and grammar features\n",
    "\n",
    "---\n",
    "\n",
    "Let's use the features we've created to construct a Logistic Regression to predict whether a review is fresh vs. rotten. \n",
    "\n",
    "Don't forget to check the baseline score, and it's a good practice to standardize your predictors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.640740894059 0.615069103879\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6150691038787338"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = rt[['objectivity_avg','pos_vs_neg_avg','quote_len']+[x for x in rt.columns if x.endswith('_prop')]]\n",
    "y = rt.fresh.values\n",
    "\n",
    "ss = StandardScaler()\n",
    "Xs = ss.fit_transform(X)\n",
    "\n",
    "lr_scores = cross_val_score(LogisticRegression(), Xs, y, cv=10)\n",
    "print np.mean(lr_scores), rt.fresh.mean()\n",
    "rt_new = rt.copy()\n",
    "rt_new['estimation'] = rt.fresh.mean()\n",
    "print r2_score(rt_new['estimation'], rt.fresh)\n",
    "rt.fresh.value_counts()\n",
    "6898.0 / (6898 + 4317)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'objectivity_avg',  u'pos_vs_neg_avg',       u'quote_len',\n",
       "              u'ADJ_prop',        u'ADP_prop',        u'ADV_prop',\n",
       "            u'CCONJ_prop',        u'DET_prop',       u'INTJ_prop',\n",
       "             u'NOUN_prop',        u'NUM_prop',       u'PART_prop',\n",
       "             u'PRON_prop',      u'PROPN_prop',      u'PUNCT_prop',\n",
       "            u'SPACE_prop',        u'SYM_prop',       u'VERB_prop',\n",
       "                u'X_prop'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objectivity_avg -0.126233159042\n",
      "pos_vs_neg_avg 0.456829490129\n",
      "quote_len 0.0972697524415\n",
      "ADJ_prop 0.0673598722125\n",
      "ADP_prop -0.00277071262457\n",
      "ADV_prop -0.116993974421\n",
      "CCONJ_prop 0.0659635231254\n",
      "DET_prop -0.0393094564402\n",
      "INTJ_prop -0.0148773028482\n",
      "NOUN_prop 0.115966462762\n",
      "NUM_prop 0.0297202568141\n",
      "PART_prop -0.0700633312946\n",
      "PRON_prop 0.0994019471933\n",
      "PROPN_prop 0.0642794454372\n",
      "PUNCT_prop -0.020160836971\n",
      "SPACE_prop -0.00129654936462\n",
      "SYM_prop 0.0122382782534\n",
      "VERB_prop -0.155693928364\n",
      "X_prop 0.0144606346576\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression().fit(Xs, y)\n",
    "for var, coef in zip(X.columns, lr.coef_[0]):\n",
    "    print var, coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The coefficients make sense for the sentiment features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=25, class_weight=None, cv=10, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "           refit=True, scoring=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# Try a lasso, find the best penalty.\n",
    "lrcv = LogisticRegressionCV(penalty='l1', solver='liblinear', Cs=25, cv=10)\n",
    "lrcv.fit(Xs, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.12168311,  0.45145997,  0.09190359,  0.06085636,  0.        ,\n",
       "        -0.11661983,  0.06352011, -0.03760395, -0.01119044,  0.10467708,\n",
       "         0.02422881, -0.06688845,  0.08826355,  0.05903704, -0.01672759,\n",
       "         0.        ,  0.00727494, -0.15485324,  0.01022316]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looks like it still keeps a fair amount of the features.\n",
    "lrcv.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "      <th>quote_len</th>\n",
       "      <th>qt</th>\n",
       "      <th>...</th>\n",
       "      <th>PART_prop</th>\n",
       "      <th>PRON_prop</th>\n",
       "      <th>PROPN_prop</th>\n",
       "      <th>PUNCT_prop</th>\n",
       "      <th>SPACE_prop</th>\n",
       "      <th>SYM_prop</th>\n",
       "      <th>VERB_prop</th>\n",
       "      <th>X_prop</th>\n",
       "      <th>objectivity_avg</th>\n",
       "      <th>pos_vs_neg_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5616</th>\n",
       "      <td>Mick LaSalle</td>\n",
       "      <td>0</td>\n",
       "      <td>120179.0</td>\n",
       "      <td>San Francisco Chronicle</td>\n",
       "      <td>They keep getting worse and worse and worse . . .</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>12541.0</td>\n",
       "      <td>Speed 2: Cruise Control</td>\n",
       "      <td>11</td>\n",
       "      <td>they keep getting worse and worse and worse</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.336648</td>\n",
       "      <td>-0.246352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5487</th>\n",
       "      <td>James Berardinelli</td>\n",
       "      <td>1</td>\n",
       "      <td>120032.0</td>\n",
       "      <td>ReelViews</td>\n",
       "      <td>At its best when it's being lighthearted and a...</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>13484.0</td>\n",
       "      <td>Romy and Michele's High School Reunion</td>\n",
       "      <td>19</td>\n",
       "      <td>at its best when it's being lighthearted and a...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.183333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  critic  fresh      imdb              publication  \\\n",
       "5616        Mick LaSalle      0  120179.0  San Francisco Chronicle   \n",
       "5487  James Berardinelli      1  120032.0                ReelViews   \n",
       "\n",
       "                                                  quote review_date     rtid  \\\n",
       "5616  They keep getting worse and worse and worse . . .  2000-01-01  12541.0   \n",
       "5487  At its best when it's being lighthearted and a...  2000-01-01  13484.0   \n",
       "\n",
       "                                       title  quote_len  \\\n",
       "5616                 Speed 2: Cruise Control         11   \n",
       "5487  Romy and Michele's High School Reunion         19   \n",
       "\n",
       "                                                     qt       ...        \\\n",
       "5616     they keep getting worse and worse and worse          ...         \n",
       "5487  at its best when it's being lighthearted and a...       ...         \n",
       "\n",
       "      PART_prop  PRON_prop  PROPN_prop  PUNCT_prop  SPACE_prop  SYM_prop  \\\n",
       "5616        0.0   0.111111         0.0         0.0    0.111111       0.0   \n",
       "5487        0.0   0.095238         0.0         0.0    0.000000       0.0   \n",
       "\n",
       "      VERB_prop  X_prop  objectivity_avg  pos_vs_neg_avg  \n",
       "5616   0.222222     0.0         0.336648       -0.246352  \n",
       "5487   0.142857     0.0         0.383333        0.183333  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='vader'></a>\n",
    "\n",
    "## Use the VADER library to get better sentiment scores\n",
    "---\n",
    "\n",
    "The [VADER](https://github.com/cjhutto/vaderSentiment) package for python is a more advanced way to calculate positivity, negativity, and objectivity in our reviews. The github page describes VADER as:\n",
    "\n",
    "> VADER Sentiment Analysis. VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media, and works well on texts from other domains.\n",
    "\n",
    "You will likely need to install VADER with pip or conda. Instructions can be found on the github page. Once you have it installed you can load the `SentimentIntensityAnalyzer` and parse text.\n",
    "\n",
    "**Parse a couple of quotes with the `SentimentIntensityAnalyzer` and print out the dictionary of scores using `analyzer.polarity_scores`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They keep getting worse and worse and worse . . .\n",
      "{'neg': 0.65, 'neu': 0.35, 'pos': 0.0, 'compound': -0.8519}\n",
      "At its best when it's being lighthearted and at its weakest when it takes a halfhearted stab at semi-seriousness.\n",
      "{'neg': 0.253, 'neu': 0.498, 'pos': 0.249, 'compound': -0.0258}\n"
     ]
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "for sentence in rt.quote.values[0:2]:\n",
    "    vs = analyzer.polarity_scores(sentence)\n",
    "    print sentence\n",
    "    print vs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that these scores look more legitimate. VADER polarity score dictionaries have 4 elements: `neg`, `pos`, `neu` and `compound`. The compound score is a single metric that represents the \"overall\" valence.\n",
    "\n",
    "**Calculate the four scores for each review and save them as features in the dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rt['vader_neg'] = 0\n",
    "rt['vader_pos'] = 0\n",
    "rt['vader_neu'] = 0\n",
    "rt['vader_compound'] = 0\n",
    "\n",
    "for i, q in enumerate(rt.quote.values):\n",
    "    vs = analyzer.polarity_scores(q)\n",
    "    rt.iloc[i, -4] = vs['neg']\n",
    "    rt.iloc[i, -3] = vs['pos']\n",
    "    rt.iloc[i, -2] = vs['neu']\n",
    "    rt.iloc[i, -1] = vs['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "      <th>quote_len</th>\n",
       "      <th>qt</th>\n",
       "      <th>...</th>\n",
       "      <th>SPACE_prop</th>\n",
       "      <th>SYM_prop</th>\n",
       "      <th>VERB_prop</th>\n",
       "      <th>X_prop</th>\n",
       "      <th>objectivity_avg</th>\n",
       "      <th>pos_vs_neg_avg</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5616</th>\n",
       "      <td>Mick LaSalle</td>\n",
       "      <td>0</td>\n",
       "      <td>120179.0</td>\n",
       "      <td>San Francisco Chronicle</td>\n",
       "      <td>They keep getting worse and worse and worse . . .</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>12541.0</td>\n",
       "      <td>Speed 2: Cruise Control</td>\n",
       "      <td>11</td>\n",
       "      <td>they keep getting worse and worse and worse</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.336648</td>\n",
       "      <td>-0.246352</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.350</td>\n",
       "      <td>-0.8519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5487</th>\n",
       "      <td>James Berardinelli</td>\n",
       "      <td>1</td>\n",
       "      <td>120032.0</td>\n",
       "      <td>ReelViews</td>\n",
       "      <td>At its best when it's being lighthearted and a...</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>13484.0</td>\n",
       "      <td>Romy and Michele's High School Reunion</td>\n",
       "      <td>19</td>\n",
       "      <td>at its best when it's being lighthearted and a...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.498</td>\n",
       "      <td>-0.0258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>Michael Wilmington</td>\n",
       "      <td>1</td>\n",
       "      <td>106220.0</td>\n",
       "      <td>Chicago Tribune</td>\n",
       "      <td>At its best, it's a valentine of venom, sent w...</td>\n",
       "      <td>2013-04-11</td>\n",
       "      <td>12634.0</td>\n",
       "      <td>Addams Family Values</td>\n",
       "      <td>14</td>\n",
       "      <td>at its best it's a valentine of venom sent wit...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>-0.075000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.8316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>Peter Travers</td>\n",
       "      <td>1</td>\n",
       "      <td>106339.0</td>\n",
       "      <td>Rolling Stone</td>\n",
       "      <td>What pulls you over the bum spots is the elect...</td>\n",
       "      <td>2007-09-10</td>\n",
       "      <td>15730.0</td>\n",
       "      <td>Backbeat</td>\n",
       "      <td>11</td>\n",
       "      <td>what pulls you over the bum spots is the elect...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>-0.364583</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>Roger Ebert</td>\n",
       "      <td>0</td>\n",
       "      <td>111127.0</td>\n",
       "      <td>Chicago Sun-Times</td>\n",
       "      <td>I am not sure why this isn't very funny, but i...</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>13696.0</td>\n",
       "      <td>Serial Mom</td>\n",
       "      <td>12</td>\n",
       "      <td>i am not sure why this isn't very funny but it...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>-0.256656</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.732</td>\n",
       "      <td>-0.3165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  critic  fresh      imdb              publication  \\\n",
       "5616        Mick LaSalle      0  120179.0  San Francisco Chronicle   \n",
       "5487  James Berardinelli      1  120032.0                ReelViews   \n",
       "1680  Michael Wilmington      1  106220.0          Chicago Tribune   \n",
       "1427       Peter Travers      1  106339.0            Rolling Stone   \n",
       "2161         Roger Ebert      0  111127.0        Chicago Sun-Times   \n",
       "\n",
       "                                                  quote review_date     rtid  \\\n",
       "5616  They keep getting worse and worse and worse . . .  2000-01-01  12541.0   \n",
       "5487  At its best when it's being lighthearted and a...  2000-01-01  13484.0   \n",
       "1680  At its best, it's a valentine of venom, sent w...  2013-04-11  12634.0   \n",
       "1427  What pulls you over the bum spots is the elect...  2007-09-10  15730.0   \n",
       "2161  I am not sure why this isn't very funny, but i...  2000-01-01  13696.0   \n",
       "\n",
       "                                       title  quote_len  \\\n",
       "5616                 Speed 2: Cruise Control         11   \n",
       "5487  Romy and Michele's High School Reunion         19   \n",
       "1680                    Addams Family Values         14   \n",
       "1427                                Backbeat         11   \n",
       "2161                              Serial Mom         12   \n",
       "\n",
       "                                                     qt       ...        \\\n",
       "5616     they keep getting worse and worse and worse          ...         \n",
       "5487  at its best when it's being lighthearted and a...       ...         \n",
       "1680  at its best it's a valentine of venom sent wit...       ...         \n",
       "1427  what pulls you over the bum spots is the elect...       ...         \n",
       "2161  i am not sure why this isn't very funny but it...       ...         \n",
       "\n",
       "      SPACE_prop  SYM_prop  VERB_prop  X_prop  objectivity_avg  \\\n",
       "5616    0.111111       0.0   0.222222     0.0         0.336648   \n",
       "5487    0.000000       0.0   0.142857     0.0         0.383333   \n",
       "1680    0.000000       0.0   0.133333     0.0         0.425000   \n",
       "1427    0.000000       0.0   0.181818     0.0         0.427083   \n",
       "2161    0.000000       0.0   0.214286     0.0         0.472222   \n",
       "\n",
       "      pos_vs_neg_avg  vader_neg  vader_pos  vader_neu  vader_compound  \n",
       "5616       -0.246352      0.650      0.000      0.350         -0.8519  \n",
       "5487        0.183333      0.253      0.249      0.498         -0.0258  \n",
       "1680       -0.075000      0.000      0.415      0.585          0.8316  \n",
       "1427       -0.364583      0.000      0.000      1.000          0.0000  \n",
       "2161       -0.256656      0.268      0.000      0.732         -0.3165  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='vader-model'></a>\n",
    "\n",
    "### Fit a model using the VADER sentiment features\n",
    "\n",
    "Does this model perform better? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.67290553  0.67023173  0.65240642  0.6684492   0.67914439  0.63636364\n",
      "  0.6372549   0.63336307  0.61785714  0.58571429]\n",
      "0.645369029049\n"
     ]
    }
   ],
   "source": [
    "X = rt[['vader_neg','vader_pos','vader_neu','vader_compound','quote_len']]\n",
    "y = rt.fresh.values\n",
    "\n",
    "Xs = StandardScaler().fit_transform(X)\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(), Xs, y, cv=10)\n",
    "print scores\n",
    "print np.mean(scores)\n",
    "\n",
    "# We do slightly better. I've also left out the part of speech stuff so that has an impact too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg -0.25445510214\n",
      "pos 0.33708994887\n",
      "neu -0.129669341392\n",
      "compound 0.159047475754\n",
      "len 0.103301240988\n"
     ]
    }
   ],
   "source": [
    "for c, v in zip(LogisticRegression().fit(Xs, y).coef_[0], ['neg','pos','neu','compound','len']):\n",
    "    print v, c\n",
    "    \n",
    "# All the coefficients make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='vader-top'></a>\n",
    "\n",
    "### Print out the top most negative, positive, neutral, and subjective features by VADER score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I hated this movie. Hated hated hated hated hated this movie. Hated it.\n",
      "---------------------------------------------------\n",
      "\n",
      "They keep getting worse and worse and worse . . .\n",
      "---------------------------------------------------\n",
      "\n",
      "What's the fourth \"Die Hard\" called? I keep forgetting. \"Die Hard: With a Pension\"? \"Die Hardened Arteries\"? \"Die Laughing\"?\n",
      "---------------------------------------------------\n",
      "\n",
      "A shambolic, deafening, intelligence-insulting mess, a crushing failure on almost all counts.\n",
      "---------------------------------------------------\n",
      "\n",
      "So distressingly dark, grim, and cynical it's likely to make kids cry!\n",
      "---------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rt.sort_values('vader_neg', ascending=False, inplace=True)\n",
    "for i in range(5):\n",
    "    print rt.quote.values[i]\n",
    "    print '---------------------------------------------------\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A truly funny, sophisticated, compassionate, mainstream Hollywood comedy about very modern homosexuality.\n",
      "---------------------------------------------------\n",
      "\n",
      "Extremely handsome production values and a great supporting cast round out the virtues.\n",
      "---------------------------------------------------\n",
      "\n",
      "For lovers of romantic comedies through the ages, Roman Holiday remains a favorite.\n",
      "---------------------------------------------------\n",
      "\n",
      "The Karate Kid exhibits warmth and friendly, predictable humor, its greatest assets.\n",
      "---------------------------------------------------\n",
      "\n",
      "Charming performances and easygoing humour are the strengths of Jones's enjoyable Oirish romp.\n",
      "---------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rt.sort_values('vader_pos', ascending=False, inplace=True)\n",
    "for i in range(5):\n",
    "    print rt.quote.values[i]\n",
    "    print '---------------------------------------------------\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Dolittle runs out of ideas long before the projector runs out of film.\n",
      "---------------------------------------------------\n",
      "\n",
      "Visually a macabre knockout, this 75-minute fantasy boasts some of the wittiest, most vigorous stop-motion animation effects in the history of the process.\n",
      "---------------------------------------------------\n",
      "\n",
      "The uneven flow is as likely to lead to a snoozing viewer as to one on the edge of their seat.\n",
      "---------------------------------------------------\n",
      "\n",
      "The plot is involving, especially as it builds to its seemingly impossible-to-solve finale.\n",
      "---------------------------------------------------\n",
      "\n",
      "Offers a departure (albeit not a radical one) from the norm.\n",
      "---------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rt.sort_values('vader_neu', ascending=False, inplace=True)\n",
    "for i in range(5):\n",
    "    print rt.quote.values[i]\n",
    "    print '---------------------------------------------------\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I hated this movie. Hated hated hated hated hated this movie. Hated it.\n",
      "---------------------------------------------------\n",
      "\n",
      "Welcome to Natural Born Killers, Stone's empty, manic meditation on society's glorification of violence and the ugly heroes it loves to hate.\n",
      "---------------------------------------------------\n",
      "\n",
      "Branagh's lame stab at a romantic psychological thriller makes no sense.\n",
      "---------------------------------------------------\n",
      "\n",
      "A truly funny, sophisticated, compassionate, mainstream Hollywood comedy about very modern homosexuality.\n",
      "---------------------------------------------------\n",
      "\n",
      "Hilarious, sexy, clever, playful and as initially teasing as it is ultimately satisfying.\n",
      "---------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rt.sort_values('vader_neu', ascending=True, inplace=True)\n",
    "for i in range(5):\n",
    "    print rt.quote.values[i]\n",
    "    print '---------------------------------------------------\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
