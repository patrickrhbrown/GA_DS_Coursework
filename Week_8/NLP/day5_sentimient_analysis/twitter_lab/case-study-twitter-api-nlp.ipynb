{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# NLP Using the Twitter API: Guided Lab\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<img src=\"https://snag.gy/RNAEgP.jpg\" width=\"600\">\n",
    "\n",
    "### Can we correctly identify which of these two old men tweeted what?\n",
    "\n",
    "> *Note: this lab is intended to be a guided lab until the independent practice questions.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "---\n",
    "\n",
    "We are going to attempt to classify whether a tweet comes from Trump or Sanders.  This lab involves multiple steps:\n",
    "- Create a developer account on Twitter\n",
    "- Create a method to pull a list of tweets from the Twitter API\n",
    "- Perform proper preprocessing on our text\n",
    "- Engineer sentiment feature in our dataset using TextBlob\n",
    "- Explore supervised classification techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter API Developer Registration\n",
    "---\n",
    "\n",
    "If you haven't registered a Twitter account yet, this is a requirement in order to have a \"developer\" account.\n",
    "\n",
    "[Twitter Rest API](https://dev.twitter.com/rest/public)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an \"App\"\n",
    "\n",
    "---\n",
    "\n",
    "![](https://snag.gy/HPBQbJ.jpg)\n",
    "\n",
    "Go to Twitter and register an \"app\" [apps.twitter.com](https://apps.twitter.com/).\n",
    "\n",
    "> **Note**: For the required website field you can put a placeholder.\n",
    "\n",
    "After you set up our app, you will only need to reference the cooresponding keys Twitter generates for our app.  These are the keys that we will use with our application to communicate with the Twitter API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Python Twitter API library\n",
    "\n",
    "---\n",
    "\n",
    "Someone was nice enough to build a Python libary for us. It makes pulling tweets simple: we only need to plug in our keys and start collecting data. The library we will be using is provided by [Python Twitter Tools](http://mike.verdone.ca/twitter/).\n",
    "\n",
    "To install it, uncomment and run the next frame (there is no conda package)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-3975cdb5d74d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-3975cdb5d74d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install twitter python-twitter\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install twitter python-twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case-study-twitter-api-nlp.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Boring Twitter Rules\n",
    "---\n",
    "\n",
    "**Twitter notifies you they will rate limit your requests:**\n",
    "\n",
    ">When using application-only authentication, rate limits are determined globally for the entire application. If a method allows for 15 requests per rate limit window, then it allows you to make 15 requests per window â€” on behalf of your application. This limit is considered completely separately from per-user limits. https://dev.twitter.com/rest/public/rate-limiting\n",
    "\n",
    "Here's a quick overview of what Twitter says are \"the rules\":\n",
    "\n",
    "![](https://snag.gy/yJ6vIH.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About those Keys: OAuth Review\n",
    "---\n",
    "\n",
    "![](https://g.twimg.com/dev/documentation/image/appauth_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's going on here?  Take a minute.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Application Keys\n",
    "---\n",
    "\n",
    "Take note of your application keys you will use to connect to Twitter and mine tweets from the official Bernie Sanders and Donald Trump twitter accounts:\n",
    "\n",
    "![](https://snag.gy/H1djQK.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `TweetMiner` class structure\n",
    "\n",
    "---\n",
    "\n",
    "The following code will get you up and running, providing connectivity to twitter. The class has the ability to make requests and can eventually transform the JSON responses into DataFrames.\n",
    "\n",
    "This is a great example of using object-oriented Python to organize our code!\n",
    "\n",
    "> **Note:** \"request_limit\" is used in this class to limit the number of tweets that are pulled per instance request.  Setting it to something lower until you've worked the bugs out of your request, and captured the data you want, is essential to avoiding the rate limit blocks.\n",
    "\n",
    "### Twitter API key setup\n",
    "\n",
    "Fill the information below in with the keys for your account.\n",
    "\n",
    "- **consumer_key** - Find this in your app page under the \"Keys and Access Tokens\"\n",
    "- **consumer_secret** - Right under **consumer_key** in the \"Keys and Access Tokens\" tab\n",
    "- **access_token_key** - You will need to click the button to generate tokens to get this\n",
    "- **access_token_secret** - Also available after you generate tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import twitter, re, datetime, pandas as pd\n",
    "from local_settings import twitter_keys\n",
    "\n",
    "# your keys go here:\n",
    "\"\"\" twitter_keys = {\n",
    "    'consumer_key':        'lA6UQplM5sxIAFr83ueUl9sgE',\n",
    "    'consumer_secret':     'f94t4BD6Vj7aCVkX1qAIVwsP4x69J2vXvm61FTIuwb9GfmdsuP',\n",
    "    'access_token_key':    '1203210464-FYE1FvoUx1GjVcoyok3U1brWDpELBJEcSNGC1OC',\n",
    "    'access_token_secret': 'kuVli1j010RPdYTbozFiIyp8QxX6PqRApdi49baLqBgzo'\n",
    "}\"\"\"\n",
    "\n",
    "api = twitter.Api(\n",
    "    consumer_key         =   twitter_keys['consumer_key'],\n",
    "    consumer_secret      =   twitter_keys['consumer_secret'],\n",
    "    access_token_key     =   twitter_keys['access_token_key'],\n",
    "    access_token_secret  =   twitter_keys['access_token_secret']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TweetMiner(object):\n",
    "\n",
    "    result_limit    =   20    \n",
    "    api             =   False\n",
    "    data            =   []\n",
    "    \n",
    "    def __init__(self, keys_dict, api, result_limit = 20):\n",
    "        \n",
    "        self.api = api\n",
    "        self.twitter_keys = keys_dict\n",
    "        \n",
    "        self.result_limit = result_limit\n",
    "        \n",
    "\n",
    "    def mine_user_tweets(self, user=\"dyerrington\", mine_rewteets=False, max_pages=5):\n",
    "\n",
    "        data           =  []\n",
    "        last_tweet_id  =  False\n",
    "        page           =  1\n",
    "        \n",
    "        while page <= max_pages:\n",
    "            \n",
    "            if last_tweet_id:\n",
    "                statuses   =   self.api.GetUserTimeline(screen_name=user, count=self.result_limit, max_id=last_tweet_id - 1)        \n",
    "            else:\n",
    "                statuses   =   self.api.GetUserTimeline(screen_name=user, count=self.result_limit)\n",
    "                \n",
    "            for item in statuses:\n",
    "\n",
    "                mined = {\n",
    "                    'tweet_id':        item.id,\n",
    "                    'handle':          item.user.name,\n",
    "                    'retweet_count':   item.retweet_count,\n",
    "                    'text':            item.text,\n",
    "                    'mined_at':        datetime.datetime.now(),\n",
    "                    'created_at':      item.created_at,\n",
    "                }\n",
    "                \n",
    "                last_tweet_id = item.id\n",
    "                data.append(mined)\n",
    "                \n",
    "            page += 1\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the class\n",
    "---\n",
    "\n",
    "Make sure you pass the keys dictionary and the api as arguments.\n",
    "\n",
    "**Check:** call the object's `mine_user_tweets()` method, providing a user to pull the tweets of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "miner = TweetMiner(twitter_keys, api, result_limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sanders = miner.mine_user_tweets(user='berniesanders', max_pages=5)\n",
    "donald = miner.mine_user_tweets(user='realDonaldTrump', max_pages=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'handle': u'Bernie Sanders', 'mined_at': datetime.datetime(2017, 4, 28, 15, 17, 48, 818830), 'created_at': u'Fri Apr 28 13:23:36 +0000 2017', 'tweet_id': 857948412540596225, 'text': u'RT @CBSNews: \"What concerns me right now is these incredible tax breaks that Pres. Trump and Republican leadership are proposing,\" @BernieS\\u2026', 'retweet_count': 314}\n"
     ]
    }
   ],
   "source": [
    "print sanders[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the tweet ouputs to a pandas DataFrame\n",
    "\n",
    "> *Hint: this is as easy as passing it to the DataFrame constructor!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>handle</th>\n",
       "      <th>mined_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Apr 28 13:23:36 +0000 2017</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>2017-04-28 15:17:48.818830</td>\n",
       "      <td>314</td>\n",
       "      <td>RT @CBSNews: \"What concerns me right now is th...</td>\n",
       "      <td>857948412540596225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fri Apr 28 12:06:56 +0000 2017</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>2017-04-28 15:17:48.818845</td>\n",
       "      <td>3047</td>\n",
       "      <td>No, @realDonaldTrump. Giving huge tax breaks t...</td>\n",
       "      <td>857929121028075521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thu Apr 27 19:50:56 +0000 2017</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>2017-04-28 15:17:49.095163</td>\n",
       "      <td>192</td>\n",
       "      <td>RT @CBSThisMorning: TOMORROW ON @CBSThisMornin...</td>\n",
       "      <td>857683503479234561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thu Apr 27 15:33:06 +0000 2017</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>2017-04-28 15:17:49.095179</td>\n",
       "      <td>320</td>\n",
       "      <td>RT @billmckibben: Watching @SenJeffMerkley @Be...</td>\n",
       "      <td>857618617684426753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed Apr 26 21:08:43 +0000 2017</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>2017-04-28 15:17:49.318354</td>\n",
       "      <td>2308</td>\n",
       "      <td>RT @keithellison: On the same day Democrats we...</td>\n",
       "      <td>857340689629237248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at          handle                   mined_at  \\\n",
       "0  Fri Apr 28 13:23:36 +0000 2017  Bernie Sanders 2017-04-28 15:17:48.818830   \n",
       "1  Fri Apr 28 12:06:56 +0000 2017  Bernie Sanders 2017-04-28 15:17:48.818845   \n",
       "2  Thu Apr 27 19:50:56 +0000 2017  Bernie Sanders 2017-04-28 15:17:49.095163   \n",
       "3  Thu Apr 27 15:33:06 +0000 2017  Bernie Sanders 2017-04-28 15:17:49.095179   \n",
       "4  Wed Apr 26 21:08:43 +0000 2017  Bernie Sanders 2017-04-28 15:17:49.318354   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0            314  RT @CBSNews: \"What concerns me right now is th...   \n",
       "1           3047  No, @realDonaldTrump. Giving huge tax breaks t...   \n",
       "2            192  RT @CBSThisMorning: TOMORROW ON @CBSThisMornin...   \n",
       "3            320  RT @billmckibben: Watching @SenJeffMerkley @Be...   \n",
       "4           2308  RT @keithellison: On the same day Democrats we...   \n",
       "\n",
       "             tweet_id  \n",
       "0  857948412540596225  \n",
       "1  857929121028075521  \n",
       "2  857683503479234561  \n",
       "3  857618617684426753  \n",
       "4  857340689629237248  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_df = pd.DataFrame(sanders)\n",
    "s_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  Create the training data\n",
    "\n",
    "---\n",
    "\n",
    "Let's get our \"mined\" data from the Twitter API.  \n",
    "\n",
    "1. Mine Trump tweets\n",
    "- Create a tweet DataFrame\n",
    "- Mine Sanders tweets\n",
    "- Append the results to our DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "miner = TweetMiner(twitter_keys, api, result_limit=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trump_tweets = miner.mine_user_tweets('realDonaldTrump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bernie_tweets = miner.mine_user_tweets('berniesanders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trump_df = pd.DataFrame(trump_tweets)\n",
    "bernie_df = pd.DataFrame(bernie_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1999, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.concat([trump_df, bernie_df], axis=0)\n",
    "tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Any interesting ngrams going on with Trump?\n",
    "---\n",
    "\n",
    "Set up a vectorizer from sklearn and fit the text of Trump's tweets with an ngram range from 2 to 4. Figure out what the most common ngrams are.\n",
    "\n",
    "> **Note:** It's up to you whether you want to remove stopwords or not. How does keeping or removing stopwords affect the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'fake news', 39),\n",
       " (u'make america', 33),\n",
       " (u'america great', 29),\n",
       " (u'watch https', 28),\n",
       " (u'make america great', 27),\n",
       " (u'united states', 23),\n",
       " (u'failing nytimes', 18),\n",
       " (u'white house', 17),\n",
       " (u'tickets https', 15),\n",
       " (u'prime minister', 14),\n",
       " (u'maga https', 14),\n",
       " (u'news media', 12),\n",
       " (u'fake news media', 11),\n",
       " (u'president obama', 10),\n",
       " (u'looking forward', 10),\n",
       " (u'north carolina', 10),\n",
       " (u'icymi watch', 10),\n",
       " (u'donald trump', 10),\n",
       " (u'president elect', 10),\n",
       " (u'hillary clinton', 10)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "# We can use the TfidfVectorizer to find ngrams for us\n",
    "vect = TfidfVectorizer(ngram_range=(2,4), stop_words=\"english\")\n",
    "\n",
    "# Pulls all of trumps tweet text's into one giant string\n",
    "summaries = \"\".join(trump_df['text'])\n",
    "ngrams_summaries = vect.build_analyzer()(summaries)\n",
    "\n",
    "Counter(ngrams_summaries).most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the ngrams for Bernie Sanders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'health care', 76),\n",
       " (u'donald trump', 64),\n",
       " (u'bernie sanders', 47),\n",
       " (u'climate change', 28),\n",
       " (u'wall street', 25),\n",
       " (u'working families', 25),\n",
       " (u'democratic party', 23),\n",
       " (u'tax breaks', 21),\n",
       " (u'american people', 21),\n",
       " (u'working people', 18),\n",
       " (u'https rt', 16),\n",
       " (u'hillary clinton', 14),\n",
       " (u'mr trump', 14),\n",
       " (u'young people', 13),\n",
       " (u'millions people', 13),\n",
       " (u'minimum wage', 13),\n",
       " (u'health insurance', 12),\n",
       " (u'drug companies', 11),\n",
       " (u'middle class', 11),\n",
       " (u'fair share', 11)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use the TfidfVectorizer to find ngrams for us\n",
    "vect = TfidfVectorizer(ngram_range=(2,4), stop_words=\"english\")\n",
    "\n",
    "# Pulls all of trumps tweet text's into one giant string\n",
    "summaries = \"\".join(bernie_df['text'])\n",
    "ngrams_summaries = vect.build_analyzer()(summaries)\n",
    "\n",
    "Counter(ngrams_summaries).most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the tweets and building a model\n",
    "\n",
    "---\n",
    "\n",
    "To do classfication we will need to convert the tweets into a set of features.\n",
    "\n",
    "**You will need to:**\n",
    "- Vectorize input text data.\n",
    "- Intialize a model (try Logistic regression).\n",
    "- Train / Predict / cross-validate.\n",
    "- Evaluate the performance of the model.\n",
    "\n",
    "> **Bonus:** you may have noticed that there are website links in the tweets. What additional preprocessing steps can you do before building the model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textacy.preprocess import preprocess_text\n",
    "\n",
    "tweet_text = tweets['text'].values\n",
    "clean_text = [preprocess_text(x, fix_unicode=True, lowercase=True, transliterate=False,\n",
    "                              no_urls=True, no_emails=True, no_phone_numbers=True, no_currency_symbols=True,\n",
    "                              no_punct=True, no_accents=True)\n",
    "              for x in tweet_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ u'We are making tremendous progress with the V. A. There has never been so much done so quickly, and we have just started. We love our VETS!'\n",
      " u'RT @foxandfriends: Former President Obama\\'s $400K Wall Street speech stuns liberal base; Sen. Warren saying she \"was troubled by that\" http\\u2026'\n",
      " u'Today, I signed an Executive Order on Improving Accountability and Whistleblower Protection at the @DeptVetAffairs:\\u2026 https://t.co/UQ6VNCyhlj']\n"
     ]
    }
   ],
   "source": [
    "print tweet_text[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'we are making tremendous progress with the v a there has never been so much done so quickly and we have just started we love our vets', u'rt foxandfriends former president obamas usd400k wall street speech stuns liberal base sen warren saying she was troubled by that http', u'today i signed an executive order on improving accountability and whistleblower protection at the deptvetaffairs url']\n"
     ]
    }
   ],
   "source": [
    "print clean_text[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.499749874937\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y = tweets['handle'].map(lambda x: 1 if x =='Donald J. Trump' else 0).values\n",
    "print np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1999, 2000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "tfv = TfidfVectorizer(ngram_range=(1, 4), max_features=2000)\n",
    "X = tfv.fit_transform(clean_text).todense()\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.865       0.925       0.935       0.935       0.905       0.935       0.855\n",
      "  0.89        0.84        0.84422111]\n",
      "0.892922110553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(LogisticRegression(), X, y, cv=10)\n",
    "\n",
    "print accuracies\n",
    "print np.mean(accuracies)\n",
    "\n",
    "estimator = LogisticRegression()\n",
    "estimator.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the predicted probability for a random Sanders and Trump tweet\n",
    "---\n",
    "\n",
    "Below are provided a couple of tweets from both Sanders and Trump. I'm sure you can figure out on your own which one is which.\n",
    "\n",
    "Estimate the predicted probability of being trump for the two tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.82093524,  0.17906476],\n",
       "       [ 0.25150094,  0.74849906]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prep our source as TfIdf vectors\n",
    "source_test = [\n",
    "    \"Demanding that the wealthy and the powerful start paying their fair share of taxes that's exactly what the American people want.\",\n",
    "    \"Crooked Hillary is spending tremendous amounts of Wall Street money on false ads against me. She is a very dishonest person!\"\n",
    "]\n",
    "\n",
    "############\n",
    "# NOTE:  Do not re-initialize the tfidf vectorizor or the feature space willbe overwritten and\n",
    "# hence your transform will not match the number of features you trained your model on.\n",
    "#\n",
    "# This is why you only need to \"transform\" since you already \"fit\" previously\n",
    "#\n",
    "####\n",
    "Xtest = tfv.transform(source_test)\n",
    "\n",
    "estimator.predict_proba(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent practice questions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pull tweets for some new users.\n",
    "\n",
    "Experiment with using more data.  The API will not like it if you blow through their limits - be careful.  Try to grab only what you need one time, then work on the copy of the objects that are returned.  \n",
    "\n",
    "> Read the documentation about rate limits and see if you can get enough without hitting the rate limit.  Are there any options available in the API to avoid such a problem?\n",
    "\n",
    "**Pull tweets for more than two different users of your choice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build a multi-class classification model to distinguish between the users.\n",
    "\n",
    "Try a new type of model than we used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Make a confusion matrix and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What is the most and least \"distinctive\" tweets for each user?\n",
    "\n",
    "To find this, identify the tweet that has the highest (correct) predicted probability of being that user's tweet for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
